import pandas as pd
import glob

# 1. crawling_data í´ë” ë‚´ ëª¨ë“  CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
data_paths = glob.glob('./crawling_data/*.csv')
df = pd.DataFrame()

for path in data_paths:
    df_temp = pd.read_csv(path)
    df_temp.columns = ['supplements', 'product', 'ingredient', 'review', 'url']
    df = pd.concat([df, df_temp], ignore_index=True)

# 1. ê³µë°± ì œê±° ë° ëŒ€ë¬¸ì ì²˜ë¦¬
df['supplements'] = df['supplements'].str.replace(" ", "").str.upper()

# 2. í‘œì¤€í™” (ë„ì–´ì“°ê¸° í¬í•¨í•´ì„œ ë³µì›)
df['supplements'] = df['supplements'].replace({
    'ë¹„íƒ€ë¯¼A': 'ë¹„íƒ€ë¯¼ A',
    'ë¹„íƒ€ë¯¼B': 'ë¹„íƒ€ë¯¼ B',
    'ë¹„íƒ€ë¯¼C': 'ë¹„íƒ€ë¯¼ C',
    'ë¹„íƒ€ë¯¼D': 'ë¹„íƒ€ë¯¼ D',
    'ë¹„íƒ€ë¯¼E': 'ë¹„íƒ€ë¯¼ E',
    'ë‚¨ì„±ìš©ë¹„íƒ€ë¯¼': 'ë‚¨ì„± ì¢…í•©ë¹„íƒ€ë¯¼',
    'ë‚¨ì„±ì¢…í•©ë¹„íƒ€ë¯¼': 'ë‚¨ì„± ì¢…í•©ë¹„íƒ€ë¯¼',
    'ì—¬ì„±ì¢…í•©ë¹„íƒ€ë¯¼': 'ì—¬ì„± ì¢…í•©ë¹„íƒ€ë¯¼',
    'ì„ì‚°ë¶€ì¢…í•©ë¹„íƒ€ë¯¼': 'ì„ì‚°ë¶€ ì¢…í•©ë¹„íƒ€ë¯¼',
})

# 3. ë¦¬ë·° ì¤‘ë³µ ì œê±° + NaN ì œê±°
# df.drop_duplicates(subset=['review'], inplace=True)
df.dropna(inplace=True)

# 4. ì €ì¥
df.to_csv('./cleaned_data/supplements.csv', index=False, encoding='utf-8-sig')
print("âœ… í†µí•© ë° ì €ì¥ ì™„ë£Œ")

# 5. ë¹„íƒ€ë¯¼ ì¢…ë¥˜ë³„ ê°œìˆ˜ í™•ì¸
supplement_counts = df['supplements'].value_counts()
print("ğŸ’Š ë¹„íƒ€ë¯¼ ì¢…ë¥˜ë³„ ì œí’ˆ ìˆ˜:")
print(supplement_counts)

# 6. ì´ ë¦¬ë·° ìˆ˜
valid_reviews = df['review'].dropna()
valid_reviews = valid_reviews[valid_reviews.str.strip() != '']
print(f"ğŸ“ ì´ ë¦¬ë·° ê°œìˆ˜: {len(valid_reviews)}ê°œ")
